{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4514b771",
   "metadata": {},
   "source": [
    "# IMMUNOPEPTIDOMICS EVIDENCE\n",
    "\n",
    "This pipeline tends to look for evidence supporting predicted neoantigens.\n",
    "At least two datasets are required.\n",
    "\n",
    "Based on: Chong and SPENCER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db32f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.getcwd()\n",
    "DATADIR=os.path.join(cwd,\"data\")\n",
    "GENERAL = DATADIR\n",
    "\n",
    "projects = [f.name for f in os.scandir(DATADIR) if f.is_dir()]\n",
    "\n",
    "###if projects names are not the GEO ids, we suggest to change them. Keys correspond to project names as they are in the folder and values the GEO id\n",
    "#dict_projects = {'liver_adjacent_totalRNA':'GSE101432', 'hcc_normal_totalRNA':'GSE77314','zou_hcc_RP_totalRNA':'GSE112705', 'GSE193567':'GSE193567'}\n",
    "#GEO = dict_projects.values()\n",
    "#GEO_list = list(GEO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d029ee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liver_adjacent_totalRNA hcc_normal_totalRNA zou_hcc_RP_totalRNA GSE193567 \n"
     ]
    }
   ],
   "source": [
    "bash_list_projects = ''\n",
    "for item in projects:\n",
    "    bash_list_projects += str(item)+' '\n",
    "print(bash_list_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "chong = pd.read_excel(os.path.join(cwd,\"immunopeptidomes_evidences/Chong_etal_2020_SupData3_41467_2020_14968_MOESM5_ESM.xlsx\"), skiprows=1)\n",
    "chong['Transcript_ID'] = chong['Transcript_ID'].str[:-2]\n",
    "to_compare_chong = chong.Sequence.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a588215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for project in projects:\n",
    "    print(project)\n",
    "    DIR = GENERAL + project\n",
    "\n",
    "    try:\n",
    "        PATIENTS=pd.read_csv(DIR+\"/results/patients.txt\", sep=\"\\t\", header=None)\n",
    "    except:\n",
    "        PATIENTS=pd.read_csv(DIR+\"/results/patients.csv\", header=None)\n",
    "\n",
    "    patients_id=list(PATIENTS.iloc[:,0])\n",
    "    folders=['noncanonical_CIPHER']\n",
    "    out=DIR+\"/analysis/14_immunopeptidomics/peptides_id_chong.csv\"\n",
    "    out_set=DIR+\"/analysis/14_immunopeptidomics/only_peptides_chong.csv\"\n",
    "    total_peptides = pd.DataFrame()\n",
    "    for f in folders:\n",
    "        for p in patients_id:\n",
    "            merged = pd.DataFrame()\n",
    "            INDIR=DIR+\"/analysis/11_PeptideBindingMHC/\"+f+\"/\"+str(p)\n",
    "\n",
    "            INFILE=pd.read_csv(INDIR+\"/\"+str(p)+\"_peptides_GTEx.csv\")\n",
    "            shared = INFILE[INFILE['Peptide'].isin(to_compare_chong)]\n",
    "            small = shared[['Peptide','transcript_id','gene_id']].drop_duplicates()\n",
    "            #print(small)\n",
    "            total_peptides = pd.concat([total_peptides,small])\n",
    "    #print(total_peptides)\n",
    "    total_peptides['type'] = np.where(total_peptides['transcript_id'].str.contains('ENST'), 'annotated', 'novel')\n",
    "    total_peptides.to_csv(out, index=False)\n",
    "\n",
    "    exclusive = pd.DataFrame(set(total_peptides.Peptide.values.tolist()))\n",
    "    exclusive.to_csv(out_set, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f689c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$GENERAL\" \"$bash_list_projects\"\n",
    "\n",
    "for project in $2; do\n",
    "    echo $project\n",
    "    cat ${1}${project}/analysis/14_immunopeptidomics/peptides_id_chong.csv | tail -n +2 | sort | uniq -c\n",
    "    #cat ${1}${project}/analysis/14_immunopeptidomics/peptides_id_chong.csv | tail -n +2 | cut -d, -f1 | sort | uniq -c\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df134dd",
   "metadata": {},
   "source": [
    "**SPENCER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83651a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "spencer = pd.read_csv(os.path.join(cwd,\"immunopeptidomes_evidences/SPENCER_Immunogenic_peptide_info.txt\"), sep=\"\\t\")\n",
    "spencer_to_compare = spencer.sequence.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8443935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for project in projects:\n",
    "    print(project)\n",
    "    DIR = GENERAL + project\n",
    "\n",
    "    try:\n",
    "        PATIENTS=pd.read_csv(DIR+\"/results/patients.txt\", sep=\"\\t\", header=None)\n",
    "    except:\n",
    "        PATIENTS=pd.read_csv(DIR+\"/results/patients.csv\", header=None)\n",
    "\n",
    "    patients_id=list(PATIENTS.iloc[:,0])\n",
    "    folders=['noncanonical_CIPHER']\n",
    "    out=DIR+\"/analysis/14_immunopeptidomics/peptides_id_spencer.csv\"\n",
    "    out_set=DIR+\"/analysis/14_immunopeptidomics/only_peptides_spencer.csv\"\n",
    "    total_peptides = pd.DataFrame()\n",
    "    for f in folders:\n",
    "        for p in patients_id:\n",
    "            merged = pd.DataFrame()\n",
    "            INDIR=DIR+\"/analysis/11_PeptideBindingMHC/\"+f+\"/\"+str(p)\n",
    "\n",
    "            INFILE=pd.read_csv(INDIR+\"/\"+str(p)+\"_peptides_GTEx.csv\")\n",
    "            shared = INFILE[INFILE['Peptide'].isin(spencer_to_compare)]\n",
    "            small = shared[['Peptide','transcript_id','gene_id']].drop_duplicates()\n",
    "            #print(small)\n",
    "            total_peptides = pd.concat([total_peptides,small])\n",
    "    #print(total_peptides)\n",
    "    total_peptides['type'] = np.where(total_peptides['transcript_id'].str.contains('ENST'), 'annotated', 'novel')\n",
    "    total_peptides.to_csv(out, index=False)\n",
    "    exclusive = pd.DataFrame(set(total_peptides.Peptide.values.tolist()))\n",
    "    exclusive.to_csv(out_set, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c865e375",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$GENERAL\" \"$bash_list_projects\"\n",
    "\n",
    "for project in $2; do\n",
    "    echo $project\n",
    "    cat ${1}${project}/analysis/14_immunopeptidomics/peptides_id_spencer.csv | tail -n +2 | sort | uniq -c\n",
    "    #cat ${1}${project}/analysis/14_immunopeptidomics/peptides_id_spencer.csv | tail -n +2 | cut -d, -f1 | sort | uniq -c\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c129c90",
   "metadata": {},
   "source": [
    "Create table : peptide | spencer/chong | novel/known | patients project1 | patients project 2 | patients project3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011c7358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_chong = pd.DataFrame()\n",
    "\n",
    "for project in projects:\n",
    "    DIR = GENERAL + project\n",
    "    try:\n",
    "        PATIENTS=pd.read_csv(DIR+\"/results/patients.txt\", sep=\"\\t\", header=None)\n",
    "    except:\n",
    "        PATIENTS=pd.read_csv(DIR+\"/results/patients.csv\", header=None)\n",
    "    patients_id=list(PATIENTS.iloc[:,0])\n",
    "    INDIR = DIR + \"/analysis/14_immunopeptidomics\"\n",
    "    os.chdir(INDIR)\n",
    "    for file in glob.glob(\"peptides_id_*csv\"):\n",
    "        if 'chong' in file:\n",
    "            chong = pd.read_csv(os.path.join(INDIR,file))\n",
    "            # First we create count column with transform\n",
    "            chong[dict_projects[project]] = chong.groupby(['Peptide', 'transcript_id']).Peptide.transform('size')\n",
    "            chong = chong.drop_duplicates()\n",
    "            total_chong = pd.concat([total_chong, chong])\n",
    "total_chong = total_chong.fillna(0)\n",
    "total_chong[GEO_list] = total_chong[GEO_list].astype(int)\n",
    "total_chong['evidence_source'] = 'Chong et al.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dee9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_chong.to_csv(os.path.join(GENERAL,\"chong_evidence_peptides.csv\"), index=False)\n",
    "total_chong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fce23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_spencer = pd.DataFrame()\n",
    "\n",
    "for project in projects:\n",
    "    DIR = GENERAL + project\n",
    "    try:\n",
    "        PATIENTS=pd.read_csv(DIR+\"/results/patients.txt\", sep=\"\\t\", header=None)\n",
    "    except:\n",
    "        PATIENTS=pd.read_csv(DIR+\"/results/patients.csv\", header=None)\n",
    "    patients_id=list(PATIENTS.iloc[:,0])\n",
    "    INDIR = DIR + \"/analysis/14_immunopeptidomics\"\n",
    "    os.chdir(INDIR)\n",
    "    for file in glob.glob(\"peptides_id_*csv\"):\n",
    "        if 'spencer' in file:\n",
    "            spencer = pd.read_csv(os.path.join(INDIR,file))\n",
    "            # First we create count column with transform\n",
    "            spencer[dict_projects[project]] = spencer.groupby(['Peptide', 'transcript_id']).Peptide.transform('size')\n",
    "            spencer = spencer.drop_duplicates()\n",
    "            total_spencer = pd.concat([total_spencer, spencer])\n",
    "total_spencer = total_spencer.fillna(0)\n",
    "total_spencer[GEO_list] = total_spencer[GEO_list].astype(int)\n",
    "total_spencer['evidence_source'] = 'SPENCER database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39019ae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_spencer.to_csv(os.path.join(GENERAL,\"spencer_evidence_peptides.csv\"), index=False)\n",
    "total_spencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71695b72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table = pd.concat([total_spencer, total_chong])\n",
    "table = table.sort_values('Peptide')\n",
    "#table = table.drop_duplicates(subset=['Peptide', 'type'])\n",
    "#table.drop('ID', inplace=True, axis=1)\n",
    "#table.to_csv(os.path.join(GENERAL,\"peptides_with_immunopeptidomics_evidence.csv\"), index=False)\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
