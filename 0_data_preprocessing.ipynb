{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDENTIFICATION OF NOVEL CLASSES OF NEOANTIGENS IN CANCER | Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data preparation\n",
    "\n",
    "This first cell should be modified according to the data that is going to be used. It is only available for datasets with paired samples per patient: normal and tumor. \n",
    "\n",
    "The **PROJECT** variable should be changed according to the GEO identifier.\n",
    "\n",
    "From the GEO website, the *SRR_Acc_List.txt* and *SraRunTable.txt* files should be manually downloaded and save in a directory. This directory should be specified in **SRR** variable.\n",
    "\n",
    "The pipeline is developed with the intention of running the most computationally expensive programs in a cluster. \n",
    "In this case, a Gluster File System has been used. The code to run on a cluster may need to be adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os,re,shutil,glob,openpyxl\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from gtfparse import read_gtf\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "PROJECT=\"GSE193567\"\n",
    "\n",
    "DIR=os.path.join(\"data\",PROJECT)\n",
    "\n",
    "try:\n",
    "    os.makedirs(DIR) #path where to store all the itermediate steps and outputs of the pipeline\n",
    "except:\n",
    "    print(\"Directory for %s already exists\" %PROJECT)\n",
    "    \n",
    "CLUSTERDIR=\"/users/genomics/marta\" #path where to run and store things that run in a cluster\n",
    "SRR=\"/projects_eg/datasets/\"+PROJECT # path where SRR_Acc_List.txt and SraRunTable.txt are stored. It should be inside a folder named with GEO accession\n",
    "SRR_ACC=os.path.join(SRR,\"SRR_Acc_List.txt\") \n",
    "SRA=os.path.join(SRR,\"SraRunTable.txt\")\n",
    "\n",
    "FASTQDIR=os.path.join(DIR,\"fastq_files\") #path where to store fastq files\n",
    "try:\n",
    "    os.mkdir(FASTQDIR)\n",
    "except:\n",
    "    print(\"Fastq_files directory exists\")\n",
    "    \n",
    "shutil.copy(SRR_ACC, os.path.join(FASTQDIR,\"SRR_Acc_List.txt\"))\n",
    "shutil.copy(SRA, os.path.join(FASTQDIR,\"SraRunTable.txt\"))\n",
    "\n",
    "GENOMEDIR=\"genomes\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.join(DIR,\"analysis\"))\n",
    "    os.makedirs(os.path.join(DIR,\"results\"))\n",
    "    #os.makedirs(os.path.join(DIR,\"scripts\"))\n",
    "except:\n",
    "    print(\"Directory exists\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "require(tidyr)\n",
    "require(dplyr)\n",
    "require(rtracklayer)\n",
    "#library(purrr)\n",
    "require(ggplot2)\n",
    "require(RColorBrewer)\n",
    "require(devtools)\n",
    "require(stringr)\n",
    "require(edgeR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a three column csv file with patient_id normal_id tumor_id for latter use. This code may need to be adjusted according to the metadata available for the dataset used. Only columns with patient id and sample id are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(FASTQDIR,\"SraRunTable.txt\"))\n",
    "metadata = metadata[['Run','Individual','tissue']]\n",
    "\n",
    "normal = metadata[metadata['tissue'] == \"non-tumor\"]\n",
    "normal = normal[['Individual','Run']]\n",
    "\n",
    "tumor = metadata[metadata['tissue'] == \"tumor\"]\n",
    "tumor = tumor[['Individual','Run']].rename(columns ={'Run' : 'Run_t'})\n",
    "\n",
    "patients = pd.merge(normal, tumor, on=['Individual'])\n",
    "patients['Individual'] = patients['Individual'].str.split(' ').str[1]\n",
    "patients.to_csv(os.path.join(DIR,\"results/patients.csv\"),index=False, header=False)\n",
    "patients_summary = os.path.join(DIR,\"results/patients.csv\")\n",
    "\n",
    "patients_id=list(patients.iloc[:,0])\n",
    "normal_id=list(patients.iloc[:,1])\n",
    "tumor_id=list(patients.iloc[:,2])\n",
    "\n",
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Download data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$CLUSTERDIR\" \"$FASTQDIR\" \"$DIR\"\n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch $4/scripts/0_data_preprocessing/loop_dwnl.sh $3 $1 $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the quality of the downloaded samples we use `md5sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$FASTQDIR\"\n",
    "\n",
    "for file in $1/*gz; do \n",
    "md5sum $file >> $1/md5sum.txt\n",
    "done\n",
    "\n",
    "md5sum --check $1/md5sum.txt >> $1/md5sum_check.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make summary file with count raw reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$FASTQDIR\" \"$DIR\"\n",
    "\n",
    "OUT=$3/results\n",
    "if [ -f \"$OUT\" ] ; then\n",
    "    rm \"$OUT\"\n",
    "fi\n",
    "for file in $2/*_1*gz; do\n",
    "    echo ${file##*/} >> $OUT/raw_counts.txt\n",
    "    zgrep '^@SRR' $file | wc -l >> $OUT/raw_counts.txt\n",
    "done    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.FastQScreen\n",
    "\n",
    "FastQ Screen allows you to screen a library of sequences in FastQ format against a set of sequence databases so you can see if the composition of the library matches with what you expect. \n",
    "\n",
    "https://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "mkdir $1/analysis/02_fastqscreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$CLUSTERDIR\" \"$FASTQDIR\" \"$DIR\" \"$GENOMEDIR\"\n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch $4/scripts/0_data_preprocessing/loop_fastqscreen.sh $1 $2 $3 $4 $5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a summary multiqc file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "cd $1/analysis/02_fastqscreen\n",
    "\n",
    "multiqc ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.FastQC\n",
    "\n",
    "Check quality of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "mkdir $1/analysis/03_fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$CLUSTERDIR\" \"$FASTQDIR\" \"$DIR\"\n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch $4/scripts/0_data_preprocessing/loop_fastqc.sh $1 $2 $3 $4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a summary multiqc file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "cd $1/analysis/03_fastqc\n",
    "\n",
    "multiqc ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04.Remove adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "mkdir $1/analysis/04_cutadapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$CLUSTERDIR\" \"$FASTQDIR\" \"$DIR\" \"$GENOMEDIR\"\n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch $4/scripts/0_data_preprocessing/loop_cutadapt.sh $1 $2 $3 $4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make summary file with count raw reads after trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "OUT=$1/results/trimmed_counts.txt\n",
    "if [ -f \"$OUT\" ] ; then\n",
    "    rm \"$OUT\"\n",
    "fi\n",
    "for file in $1/analysis/04_cutadapt/*_1*gz; do\n",
    "    echo ${file##*/} >> $OUT\n",
    "    zgrep '^@SRR' $file | wc -l >> $OUT\n",
    "done    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastQC after trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "mkdir $1/analysis/04_cutadapt/fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$CLUSTERDIR\" \"$DIR\"\n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch $3/scripts/0_data_preprocessing/loop_fastqc_trimming.sh $1 $2 $3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a summary multiqc file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "cd $1/analysis/04_cutadapt/fastqc\n",
    "\n",
    "multiqc ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.Alignment on *H.sapiens* Genome v.38\n",
    "\n",
    "To do the alignment, STAR program is used with 2pass option and keeping only uniquely mapped reads.\n",
    "\n",
    "First the index(es) must be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$GENOMEDIR\"\n",
    "\n",
    "mkdir $1/Index_Genomes_STAR\n",
    "mkdir $1/Index_Genomes_STAR/Idx_Gencode_v38_hg38_readlength75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$CLUSTERDIR\" \"$GENOMEDIR\" \"$DIR\"\n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch $3/scripts/0_data_preprocessing/index.sh $1 $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now indexes are stored in `$GENOMEDIR/Index_Genomes_STAR/Idx_Gencode_v38_hg38_readlength75`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "mkdir $1/analysis/05_STAR\n",
    "mkdir $1/analysis/05_STAR/uniquely_mapped_2pass_BAM_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$CLUSTERDIR\" \"$DIR\" \"$GENOMEDIR\"\n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch $3/scripts/0_data_preprocessing/loop_STAR.sh $1 $2 $3 $4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid future problems dealing with multimapping reads, we only keep the uniquely mapped ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make summary file with uniquely mapped reads and the percentage they represent from the whole alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "OUT=$1/results/uniquely_mapped_reads.txt\n",
    "if [ -f \"$OUT\" ] ; then\n",
    "    rm \"$OUT\"\n",
    "fi\n",
    "echo -e \"Sample\\tUniquely_mapped_reads\\t%alignment\" >> $OUT\n",
    "\n",
    "for file in $1/analysis/05_STAR/uniquely_mapped_2pass_BAM_files/*Log.final.out; do\n",
    "    name=${file%%Log*}\n",
    "    name=${name##*BAM_files/}\n",
    "    echo -e $name\"\\t\"$(sed '9q;d' $file | awk '{print $6}')\"\\t\"$(sed '10q;d' $file | awk '{print $6}') >> $OUT\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
