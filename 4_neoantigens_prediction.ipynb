{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDENTIFICATION OF NOVEL CLASSES OF NEOANTIGENS IN CANCER | Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data preparation\n",
    "\n",
    "This first cell should be modified according to the data that is going to be used. It is only available for datasets with paired samples per patient: normal and tumor. \n",
    "\n",
    "The **PROJECT** variable should be changed according to the GEO identifier.\n",
    "\n",
    "From the GEO website, the *SRR_Acc_List.txt* and *SraRunTable.txt* files should be manually downloaded and save in a directory. This directory should be specified in **SRR** variable.\n",
    "\n",
    "The pipeline is developed with the intention of running the most computationally expensive programs in a cluster. \n",
    "In this case, a Gluster File System has been used. The code to run on a cluster may need to be adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os,re,shutil,glob,openpyxl\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from gtfparse import read_gtf\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "PROJECT=\"GSE193567\"\n",
    "\n",
    "DIR=os.path.join(\"data\",PROJECT)\n",
    "\n",
    "try:\n",
    "    os.makedirs(DIR) #path where to store all the itermediate steps and outputs of the pipeline\n",
    "except:\n",
    "    print(\"Directory for %s already exists\" %PROJECT)\n",
    "    \n",
    "CLUSTERDIR=\"/users/genomics/marta\" #path where to run and store things that run in a cluster\n",
    "SRR=\"/projects_eg/datasets/\"+PROJECT # path where SRR_Acc_List.txt and SraRunTable.txt are stored. It should be inside a folder named with GEO accession\n",
    "SRR_ACC=os.path.join(SRR,\"SRR_Acc_List.txt\") \n",
    "SRA=os.path.join(SRR,\"SraRunTable.txt\")\n",
    "\n",
    "FASTQDIR=os.path.join(DIR,\"fastq_files\") #path where to store fastq files\n",
    "try:\n",
    "    os.mkdir(FASTQDIR)\n",
    "except:\n",
    "    print(\"Fastq_files directory exists\")\n",
    "    \n",
    "shutil.copy(SRR_ACC, os.path.join(FASTQDIR,\"SRR_Acc_List.txt\"))\n",
    "shutil.copy(SRA, os.path.join(FASTQDIR,\"SraRunTable.txt\"))\n",
    "\n",
    "GENOMEDIR=\"genomes\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(os.path.join(DIR,\"analysis\"))\n",
    "    os.makedirs(os.path.join(DIR,\"results\"))\n",
    "    #os.makedirs(os.path.join(DIR,\"scripts\"))\n",
    "except:\n",
    "    print(\"Directory exists\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "require(tidyr)\n",
    "require(dplyr)\n",
    "require(rtracklayer)\n",
    "#library(purrr)\n",
    "require(ggplot2)\n",
    "require(RColorBrewer)\n",
    "require(devtools)\n",
    "require(stringr)\n",
    "require(edgeR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a three column file with patient_id normal_id tumor_id for latter usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Individual</th>\n",
       "      <th>Run</th>\n",
       "      <th>Run_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10615</td>\n",
       "      <td>SRR17593537</td>\n",
       "      <td>SRR17593538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10594</td>\n",
       "      <td>SRR17593539</td>\n",
       "      <td>SRR17593540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10584</td>\n",
       "      <td>SRR17593542</td>\n",
       "      <td>SRR17593541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10635</td>\n",
       "      <td>SRR17593543</td>\n",
       "      <td>SRR17593544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10632</td>\n",
       "      <td>SRR17593546</td>\n",
       "      <td>SRR17593545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10628</td>\n",
       "      <td>SRR17593548</td>\n",
       "      <td>SRR17593547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10627</td>\n",
       "      <td>SRR17593550</td>\n",
       "      <td>SRR17593549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10622</td>\n",
       "      <td>SRR17593551</td>\n",
       "      <td>SRR17593552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10619</td>\n",
       "      <td>SRR17593554</td>\n",
       "      <td>SRR17593553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Individual          Run        Run_t\n",
       "0      10615  SRR17593537  SRR17593538\n",
       "1      10594  SRR17593539  SRR17593540\n",
       "2      10584  SRR17593542  SRR17593541\n",
       "3      10635  SRR17593543  SRR17593544\n",
       "4      10632  SRR17593546  SRR17593545\n",
       "5      10628  SRR17593548  SRR17593547\n",
       "6      10627  SRR17593550  SRR17593549\n",
       "7      10622  SRR17593551  SRR17593552\n",
       "8      10619  SRR17593554  SRR17593553"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(os.path.join(FASTQDIR.split(\"/fastq_files\")[0],\"SraRunTable.txt\"))\n",
    "metadata = metadata[['Run','Individual','tissue']]\n",
    "\n",
    "normal = metadata[metadata['tissue'] == \"non-tumor\"]\n",
    "normal = normal[['Individual','Run']]\n",
    "\n",
    "tumor = metadata[metadata['tissue'] == \"tumor\"]\n",
    "tumor = tumor[['Individual','Run']].rename(columns ={'Run' : 'Run_t'})\n",
    "\n",
    "patients = pd.merge(normal, tumor, on=['Individual'])\n",
    "patients['Individual'] = patients['Individual'].str.split(' ').str[1]\n",
    "patients.to_csv(os.path.join(DIR,\"results/patients.csv\"),index=False, header=False)\n",
    "patients_summary = os.path.join(DIR,\"results/patients.csv\")\n",
    "\n",
    "patients_id=list(patients.iloc[:,0])\n",
    "normal_id=list(patients.iloc[:,1])\n",
    "tumor_id=list(patients.iloc[:,2])\n",
    "\n",
    "patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.HLAtyping\n",
    "\n",
    "The programm needs a fasta file and if it is rna or dna and then it first only takes the parts of chromosome 6 that encode the HLA-I and gives you predictions. I ran it with --enumerations 3, so it gives the three most likely predictions. But in the end I only used the best prediction. And I have several samples per patient. So what I did is run it for all (tumour DNA, blood DNA, tumour RNA, post-treatment samples etc), took only the best predcition and checked if it is the same HLA Allele Typing in all samples (whcih it should be). And when it was different between samples of the same patient, I looked at the quality (coverage plots provided by the program) and then it was ususally quite clear that for samples where the prediction differed the coverage was low...\n",
    "\n",
    "https://github.com/nf-core/hlatyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "mkdir $1/analysis/10_HLAtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$FASTQDIR\" \"$CLUSTERDIR\" \"$DIR\" \"$patients_summary\"\n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch $3/scripts/4_neoantigens_prediction/loop_hla.sh $1 $2 $3 $4 $5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate HLA alleles file from the specific dataset and for its latter usage in netMHCpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "counter=0\n",
    "OUT=DIR+\"/analysis/10_HLAtyping/hla_alleles_patients.csv\"\n",
    "with open(OUT, 'w') as out:\n",
    "    for p in patients_id:\n",
    "        out_df = pd.DataFrame()\n",
    "        with open (DIR+\"/analysis/10_HLAtyping/\"+p+\"/optitype/\"+normal_id[counter]+\"/\"+normal_id[counter]+\"_result.tsv\") as hlatyping:\n",
    "            lines = hlatyping.readlines()\n",
    "            del lines[0]\n",
    "            line = lines[1].strip()\n",
    "            splitted_line = line.split(\"\\t\")\n",
    "            del splitted_line[0]\n",
    "            del splitted_line[6]\n",
    "            del splitted_line[6]\n",
    "            listToStr = '\\t'.join(map(str, splitted_line))\n",
    "            listToStr = listToStr.strip()\n",
    "            out.write(\"%s\\t%s\\n\" %(p, listToStr))\n",
    "        \n",
    "        counter = counter + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\"\n",
    "\n",
    "hlatyping=$1/analysis/10_HLAtyping/hla_alleles_patients.csv\n",
    "\n",
    "cut -d, -f2- $hlatyping > ${hlatyping%%_patients*}.csv\n",
    "< ${hlatyping%%_patients*}.csv tr -s '\\t' '\\n' | sort | uniq > ${hlatyping%%_patients*}_uniq.csv\n",
    "\n",
    "sed -i -e 's/^/HLA-/' ${hlatyping%%_patients*}_uniq.csv \n",
    "\n",
    "< ${hlatyping%%_patients*}_uniq.csv tr -s '\\n' ',' > $1/analysis/10_HLAtyping/alleles.txt\n",
    "sed -i 's/\\*//g' $1/analysis/10_HLAtyping/alleles.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A*02:01,HLA-A*29:10,HLA-B*44:03,HLA-B*44:03,HLA-C*16:01,HLA-C*16:01\n",
      "A02:01,HLA-A29:10,HLA-B44:03,HLA-B44:03,HLA-C16:01,HLA-C16:01\n",
      "A*02:01,HLA-A*30:02,HLA-B*44:03,HLA-B*44:22,HLA-C*05:01,HLA-C*16:01\n",
      "A02:01,HLA-A30:02,HLA-B44:03,HLA-B44:22,HLA-C05:01,HLA-C16:01\n",
      "A*02:01,HLA-A*02:29,HLA-B*35:01,HLA-B*49:01,HLA-C*04:01,HLA-C*07:01\n",
      "A02:01,HLA-A02:29,HLA-B35:01,HLA-B49:01,HLA-C04:01,HLA-C07:01\n",
      "A*11:01,HLA-A*32:01,HLA-B*35:08,HLA-B*49:01,HLA-C*04:01,HLA-C*07:01\n",
      "A11:01,HLA-A32:01,HLA-B35:08,HLA-B49:01,HLA-C04:01,HLA-C07:01\n",
      "A*32:01,HLA-A*32:01,HLA-B*35:03,HLA-B*44:03,HLA-C*04:01,HLA-C*16:01\n",
      "A32:01,HLA-A32:01,HLA-B35:03,HLA-B44:03,HLA-C04:01,HLA-C16:01\n",
      "A*11:01,HLA-A*24:10,HLA-B*08:01,HLA-B*38:01,HLA-C*07:01,HLA-C*12:03\n",
      "A11:01,HLA-A24:10,HLA-B08:01,HLA-B38:01,HLA-C07:01,HLA-C12:03\n",
      "A*01:01,HLA-A*30:01,HLA-B*08:01,HLA-B*49:01,HLA-C*07:01,HLA-C*12:03\n",
      "A01:01,HLA-A30:01,HLA-B08:01,HLA-B49:01,HLA-C07:01,HLA-C12:03\n",
      "A*01:01,HLA-A*30:02,HLA-B*08:01,HLA-B*18:01,HLA-C*07:01,HLA-C*05:09\n",
      "A01:01,HLA-A30:02,HLA-B08:01,HLA-B18:01,HLA-C07:01,HLA-C05:09\n",
      "A*02:01,HLA-A*24:10,HLA-B*39:06,HLA-B*50:01,HLA-C*06:02,HLA-C*07:02\n",
      "A02:01,HLA-A24:10,HLA-B39:06,HLA-B50:01,HLA-C06:02,HLA-C07:02\n"
     ]
    }
   ],
   "source": [
    "#HLA alleles separated by , to pass to netMHCpan directly\n",
    "alleles=DIR+\"/analysis/10_HLAtyping/hla_alleles_patients.csv\"\n",
    "#the file will contain all the HLA I alleles per patient written in such a way that no further cleaning is need for netMHCpan to use them\n",
    "for p in patients_id:\n",
    "    OUT=DIR+\"/analysis/10_HLAtyping/\"+p+\"_alleles_to_netMHCpan.csv\"\n",
    "    with open(OUT, 'w') as out:\n",
    "        with open(alleles) as inp:\n",
    "            lines=inp.readlines()\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                splitted_line=line.split(\"\\t\")\n",
    "                patient=splitted_line.pop(0)\n",
    "                if patient == p:\n",
    "                    listToStr = ',HLA-'.join(map(str, splitted_line))\n",
    "                    listToStr = listToStr.replace(\"*\",\"\")\n",
    "                    out.write(\"HLA-\"+listToStr+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.PeptideBindingMHC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the length of the peptides, we analyzed the Supplementary Table S3 of \n",
    "\n",
    "Chong, C., MÃ¼ller, M., Pak, H. et al. Integrated proteogenomic deep sequencing and analytics accurately identify non-canonical peptides in tumor immunopeptidomes. Nat Commun 11, 1293 (2020). https://doi.org/10.1038/s41467-020-14968-9\n",
    "\n",
    "We used it as a kind of database to support our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$GENOMEDIR\"\n",
    "mkdir $1/chongetal\n",
    "cd $1/chongetal\n",
    "\n",
    "wget https://static-content.springer.com/esm/art%3A10.1038%2Fs41467-020-14968-9/MediaObjects/41467_2020_14968_MOESM5_ESM.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abundance 8/9/10/11 aa peptides\n",
    "chong = pd.read_excel(os.path.join(GENOMEDIR,\"/chonetal/Chong_etal_2020_SupData3_41467_2020_14968_MOESM5_ESM.xlsx\", skiprows=1)\n",
    "chong['Transcript_ID'] = chong['Transcript_ID'].str[:-2]\n",
    "list_seqs = chong.Sequence.values.tolist()\n",
    "total_num_peptides=len(list_seqs)\n",
    "counter8 = 0\n",
    "counter9 = 0\n",
    "counter10 = 0\n",
    "counter11 = 0\n",
    "\n",
    "for peptide in list_seqs:\n",
    "    if len(peptide) == 8:\n",
    "        counter8 = counter8 + 1\n",
    "    if len(peptide) == 9:\n",
    "        counter9 = counter9 + 1\n",
    "    if len(peptide) == 10:\n",
    "        counter10 = counter10 + 1\n",
    "    if len(peptide) == 11:\n",
    "        counter11 = counter11 + 1\n",
    "\n",
    "print(\"There are:\\n%i 8aa peptides\\n%i 9aa peptides\\n%i 10aa peptides\\n%i 11aapeptides\" %(counter8,counter9,counter10,counter11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9aa peptides are the ones with more binding affinity, according to Chong et al. Supplementary Table S3. So we are going to use 9aa peptides.\n",
    "\n",
    "To be able to jump to conclusions and compare results, we will predict the binding affinity of peptides derived from several strategies:\n",
    "\n",
    "**A** | due to expression of tumor-specific putative noncanonical ORFS (CIPHER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists\n",
      "Directory already exists, data could be overwritten.\n",
      "Directory already exists, data could be overwritten.\n",
      "Directory already exists, data could be overwritten.\n",
      "Directory already exists, data could be overwritten.\n",
      "Directory already exists, data could be overwritten.\n",
      "Directory already exists, data could be overwritten.\n",
      "Directory already exists, data could be overwritten.\n",
      "Directory already exists, data could be overwritten.\n",
      "Directory already exists, data could be overwritten.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs(DIR+\"/analysis/11_PeptideBindingMHC/noncanonical_CIPHER\")\n",
    "except:\n",
    "    print(\"Directory already exists\")\n",
    "    \n",
    "for p in patients_id:\n",
    "    INDIR=DIR+\"/analysis/09_CIPHER/\"+p\n",
    "    OUTDIR=DIR+\"/analysis/11_PeptideBindingMHC/noncanonical_CIPHER/\"+p\n",
    "    try:\n",
    "        os.mkdir(OUTDIR)\n",
    "    except:\n",
    "        print(\"Directory already exists, data could be overwritten.\")\n",
    "    file= p + \"_noncanonical_all_orfs_FPKM1_notduplis_PROTEIN.fa\" \n",
    "    outfile = file[:-3] + \"_9aa.fa\"\n",
    "    with open (os.path.join(OUTDIR,outfile), 'w') as out:\n",
    "        for seq_record in SeqIO.parse(os.path.join(INDIR,file), \"fasta\"):\n",
    "            if len(seq_record.seq) >= 9: # we keep only sequences with > 9 aminoacids so they can be cut into little peptides. Really small sequences with less than 9 aa would not bind to the MHC.\n",
    "                out.write(\">\" + seq_record.id + \"\\n\" + str(seq_record.seq) + \"\\n\")\n",
    "            else:\n",
    "                next\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary file with the amount of sequences with more than 9aa with respect to the total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\" \"$patients_summary\"\n",
    "\n",
    "OUT=$1/results/sequences_9aa.txt\n",
    "if [ -f \"$OUT\" ] ; then\n",
    "    rm \"$OUT\"\n",
    "fi\n",
    "cat $2 | while IFS=, read p normal tumor; do\n",
    "INDIR=$1/analysis/09_CIPHER/${p}\n",
    "LONG_DIR=$1/analysis/11_PeptideBindingMHC/noncanonical_CIPHER/${p}\n",
    "echo -e ${p}\" full_length: \"$(grep '>' ${INDIR}/${p}_noncanonical_all_orfs_FPKM1_notduplis_PROTEIN.fa | wc -l) >> $OUT\n",
    "echo -e ${p}\" more than 9 aa: \"$(grep '>' ${LONG_DIR}/${p}_noncanonical_all_orfs_FPKM1_notduplis_PROTEIN_9aa.fa | wc -l) >> $OUT\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean header\n",
    "for p in patients_id:\n",
    "    INDIR=DIR+\"/analysis/11_PeptideBindingMHC/noncanonical_CIPHER/\"+p\n",
    "    for file in os.listdir(INDIR):\n",
    "        if file.endswith(\"9aa.fa\"):\n",
    "            outfile = file[:-3] + \"_cleanheader.fa\"\n",
    "\n",
    "            with open (os.path.join(INDIR,outfile), 'w') as out:\n",
    "                for seq_record in SeqIO.parse(os.path.join(INDIR,file), \"fasta\"):\n",
    "                    if \"ENST\" in seq_record.id:\n",
    "                        identifier = seq_record.id.split(\".\")[0]\n",
    "                        identifier = identifier + \";\" + seq_record.id[-1]\n",
    "                    else:\n",
    "                        identifier = seq_record.id.split(\",\")[0]\n",
    "                        identifier = identifier[:-2] + \";\" + seq_record.id[-1]\n",
    "\n",
    "                    out.write(\">%s\\n%s\\n\" %(str(identifier),str(seq_record.seq)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NetMHCpan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$DIR\" \"$CLUSTERDIR\" \n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch --array=1-9 $2/scripts/4_neoantigen_prediction/netmhcpan_noncanonical.sh $1 $2 $3 #--array=1-n where n is the number of files to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B** | Due to expression of tumor-specific canonical CDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marta/.local/lib/python3.9/site-packages/Bio/Seq.py:2979: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for p in patients_id:\n",
    "    INDIR=DIR+\"/analysis/08_tumor_specific/\"+p\n",
    "    file=p + \"_known_tumor_specific_genes_1FPKM_300kb_CDS_gene.fa\"\n",
    "    outfile = file[:-3] + \"_PROTEIN.fa\"\n",
    "    with open (os.path.join(INDIR,outfile), 'w') as out:\n",
    "        for seq_record in SeqIO.parse(os.path.join(INDIR,file), \"fasta\"):\n",
    "            identif=str(seq_record.id)\n",
    "            sequence=str(seq_record.seq.translate())\n",
    "            out.write(\">\" + identif + \"\\n\" + sequence[:-1] + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NetMHCpan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$DIR\" \"$CLUSTERDIR\" \n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch --array=1-9 $2/scripts/4_neoantigen_prediction/netmhcpan_canonical.sh $1 $2 $3 #--array=1-n where n is the number of files to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C** | NOCDS with translation evidence\n",
    "\n",
    "We have two sets of ribo-seq data to compare our finding with translation evidence. To do so, we compare at indetifier level, if what we considered as non-canonical with coding potential is supported by ribo seq data\n",
    "\n",
    "*Ouspenskaia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists, data may be overwritten\n",
      "Directory already exists, data may be overwritten\n",
      "Directory already exists, data may be overwritten\n",
      "Directory already exists, data may be overwritten\n",
      "Directory already exists, data may be overwritten\n",
      "Directory already exists, data may be overwritten\n",
      "Directory already exists, data may be overwritten\n",
      "Directory already exists, data may be overwritten\n",
      "Directory already exists, data may be overwritten\n"
     ]
    }
   ],
   "source": [
    "ouspenskaia=pd.read_csv(os.path.join(cwd,\"riboseq_evidences/ouspenskaia.lncRNA.20220222.csv\"))\n",
    "\n",
    "for p in patients_id:\n",
    "    try:\n",
    "        os.makedirs(DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+p)\n",
    "    except:\n",
    "        print(\"Directory already exists, data may be overwritten\")\n",
    "        \n",
    "    NOCDS=DIR+\"/analysis/08_tumor_specific/\"+p+\"/\"+p+\"_known_tumor_specific_genes_1FPKM_300kb_NOCDS_selected.csv\" # from all nocds tumor specific transcripts,\n",
    "    OUTNOCDS=DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+ p + \"/\" + p +\"_translation_evidence_ouspenskaia.txt\" #how many of them are present in ribo-seq set of data from Ouspenskaia\n",
    "    OUTNOCDS_list=DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+ p + \"/\" + p +\"_translation_evidence_ouspenskaia_ids.txt\" #and generate also a list\n",
    "\n",
    "    df = pd.read_csv(NOCDS)\n",
    "    list_df = df.gene_id.values.tolist()\n",
    "    list_df_clean = [x.split(\".\")[0] for x in list_df]\n",
    "    shared = ouspenskaia[ouspenskaia['gene'].isin(list_df_clean)]\n",
    "    shared.to_csv(OUTNOCDS, index=False, header=True)\n",
    "    shared.iloc[:,2].to_csv(OUTNOCDS_list, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a summary file with the number of non-protein coding genes present in ouspenskaia database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\" \"$patients_summary\"\n",
    "\n",
    "OUT=$1/results/overlap_w_ouspenskaia.txt\n",
    "if [ -f \"$OUT\" ] ; then\n",
    "    rm \"$OUT\"\n",
    "fi\n",
    "cat $2 | while IFS=, read p normal tumor; do\n",
    "    file=$1/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/${p}/${p}_translation_evidence_ouspenskaia_ids.txt\n",
    "    echo -e $p\"\\t\"$(wc -l < $file) >> $OUT \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*HCC*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcc=pd.read_csv(os.path.join(cwd,\"riboseq_evidences/HCC_tumor.lncRNA.20220222.csv\"))\n",
    "\n",
    "for p in patients_id:     \n",
    "    NOCDS=DIR+\"/analysis/08_tumor_specific/\"+p+\"/\"+p+\"_known_tumor_specific_genes_1FPKM_300kb_NOCDS_selected.csv\"\n",
    "    OUTNOCDS=DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+ p + \"/\" + p +\"_translation_evidence_hcc.txt\"\n",
    "    OUTNOCDS_list=DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+ p + \"/\" + p +\"_translation_evidence_hcc_ids.txt\"\n",
    "\n",
    "    df = pd.read_csv(NOCDS)\n",
    "    list_df = df.gene_id.values.tolist()\n",
    "    list_df_clean = [x.split(\".\")[0] for x in list_df]\n",
    "    shared = hcc[hcc['gene'].isin(list_df_clean)]\n",
    "    shared.to_csv(OUTNOCDS, index=False, header=True)\n",
    "    shared.iloc[:,2].to_csv(OUTNOCDS_list, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a summary file with the number of non-protein coding genes present in hcc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$DIR\" \"$patients_summary\"\n",
    "\n",
    "OUT=$1/results/overlap_w_hcc.txt\n",
    "if [ -f \"$OUT\" ] ; then\n",
    "    rm \"$OUT\"\n",
    "fi\n",
    "cat $2 | while IFS=, read p normal tumor; do\n",
    "    file=$1/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/${p}/${p}_translation_evidence_hcc_ids.txt\n",
    "    echo -e $p\"\\t\"$(wc -l < $file) >> $OUT \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate both overlapping genes with the translation evidence datasets avoiding redundancies in such a way that we will be generating a file with those nonprotein coding genes we detected and with translation evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10615\t3\n",
      "10594\t14\n",
      "10584\t4\n",
      "10635\t6\n",
      "10632\t3\n",
      "10628\t4\n",
      "10627\t2\n",
      "10622\t9\n",
      "10619\t10\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$DIR\" \"$patients_summary\"\n",
    "\n",
    "cat $2  | while IFS=, read p normal tumor; do\n",
    "INDIR=$1/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/${p}\n",
    "cat ${INDIR}/${p}*ids.txt | sort | uniq > ${INDIR}/${p}_translational_evidence.txt\n",
    "echo -e $p\"\\t\"$(wc -l < ${INDIR}/${p}_translational_evidence.txt) \n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate mini gtf of those lncRNA and pseudogenes tumor specific with coding potential according to two sources of RIbo-Seq data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10615\n",
      "10594\n",
      "10584\n",
      "10635\n",
      "10632\n",
      "10628\n",
      "10627\n",
      "10622\n",
      "10619\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for p in patients_id:\n",
    "    print(p)\n",
    "    REF=DIR+\"/analysis/06_stringtie/stringtie_reference_annotations/\"+tumor_id[counter]+\"_reference_annotation_sorted.gtf\"     \n",
    "    with open(REF) as annotations:\n",
    "        annotation_lines = annotations.readlines()\n",
    "        csv_file=pd.read_csv(DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+p+\"/\"+p+\"_translational_evidence.txt\", header=None)\n",
    "        g_id = []\n",
    "        g_id = list(csv_file.iloc[:,0])\n",
    "        OUT=DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+p+\"/\"+p+\"_translational_evidence.gtf\"\n",
    "\n",
    "        with open(OUT, 'w') as out:\n",
    "            for line in annotation_lines:\n",
    "                if line.startswith('#'):\n",
    "                    next\n",
    "                else:\n",
    "                    splitted_line = line.split(\";\")\n",
    "                    ENST = splitted_line[1]\n",
    "                    ENST = re.findall('\"([^\"]*)\"', ENST)[0]\n",
    "                    if ENST.split(\".\")[0] in g_id:\n",
    "                        out.write(line)\n",
    "\n",
    "    counter = counter + 1\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fasta sequence of open reading frames from CIPHER that have ribo-seq support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in patients_id:\n",
    "    file=DIR+\"/analysis/09_CIPHER/\"+p+\"/\"+p+\"_known_tumor_specific_genes_1FPKM_300kb_NOCDS_selected_8aa_cipher_all_orfs.fa\"\n",
    "    ids=list(pd.read_csv(DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+p+\"/\"+p+\"_translational_evidence.txt\", header=None).iloc[:,0])\n",
    "    OUT=DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+p+\"/\"+p+\"_translational_evidence.fa\"\n",
    "    with open(OUT, 'w') as out:\n",
    "        for seq_record in SeqIO.parse(file, 'fasta'):\n",
    "            if seq_record.id.split('.')[0] in ids:\n",
    "                out.write(\">%s\\n%s\\n\" %(seq_record.id, seq_record.seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10615\t6\n",
      "10594\t23\n",
      "10584\t8\n",
      "10635\t10\n",
      "10632\t2\n",
      "10628\t3\n",
      "10627\t0\n",
      "10622\t12\n",
      "10619\t8\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$DIR\" \"$patients_summary\"\n",
    "\n",
    "cat $2 | while IFS=, read p normal tumor; do\n",
    "file=$1/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/${p}/${p}_translational_evidence.fa\n",
    "echo -e $p\"\\t\"$(grep '>' $file | wc -l) #orfs\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PYTHON VENN DIAGRAMS PER PATIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "set1 = set(ouspenskaia['trans'])\n",
    "set2 = set(hcc['trans'])\n",
    "\n",
    "venn2([set1,set2], ('Ouspenskaia','HCC'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#how many sequences are supported by both sources of evidence per patient\n",
    "for p in patients_id:\n",
    "    ouspenskaia = pd.read_csv(DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+p+\"/\"+p+\"_translation_evidence_ouspenskaia.txt\")\n",
    "    if os.path.getsize(DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+p+\"/\"+p+\"_translation_evidence_hcc.txt\") > 1: #is file is not empty\n",
    "        hcc = pd.read_csv(DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+p+\"/\"+p+\"_translation_evidence_hcc.txt\")\n",
    "\n",
    "        set1 = set(ouspenskaia['trans'])\n",
    "        set2 = set(hcc['trans'])\n",
    "\n",
    "        venn2([set1,set2], ('Ouspenskaia','HCC'), set_colors=(\"#fdae6b\", \"#8856a7\"), alpha = 0.7)\n",
    "        plt.title(p)\n",
    "        plt.savefig(DIR+\"/results/plots/\"+p+\"_venndiagram_translation_evidence.jpeg\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate\n",
    "for p in patients_id:\n",
    "    INDIR=DIR+\"/analysis/11_PeptideBindingMHC/translation_evidence_NOCDS/\"+p\n",
    "    file= p + \"_translational_evidence.fa\"\n",
    "    outfile = file[:-3] + \"_PROTEIN.fa\"\n",
    "    with open (os.path.join(INDIR,outfile), 'w') as out:\n",
    "        for seq_record in SeqIO.parse(os.path.join(INDIR,file), \"fasta\"):\n",
    "            identif=str(seq_record.id)\n",
    "            sequence=str(seq_record.seq.translate())\n",
    "            out.write(\">\" + identif + \"\\n\" + sequence[:-1] + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NetMHCpan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$PROJECT\" \"$DIR\" \"$CLUSTERDIR\" \n",
    "\n",
    "######################################DONE IN CLUSTER###############################################\n",
    "\n",
    "sbatch --array=1-9 $2/scripts/4_neoantigen_prediction/netmhcpan_te.sh $1 $2 $3 #--array=1-n where n is the number of files to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring netMHCpan output.\n",
    "\n",
    "Summary file **A** with peptides with binding affinity for at least 1 HLA allele + ENST + ENSG for each canonical / noncanonical with CIPHER / translation evidence \n",
    "\n",
    "Summary file **B** how many peptides have binding affinity respect to the total number of peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noncanonical_CIPHER\n",
      "10615\n",
      "10594\n",
      "10584\n",
      "10635\n",
      "10632\n",
      "10628\n",
      "10627\n",
      "10622\n",
      "10619\n",
      "canonical_CDS\n",
      "10615\n",
      "10594\n",
      "10584\n",
      "10635\n",
      "10632\n",
      "10628\n",
      "10627\n",
      "10622\n",
      "10619\n",
      "translation_evidence_NOCDS\n",
      "10615\n",
      "10594\n",
      "10584\n",
      "10635\n",
      "10632\n",
      "10628\n",
      "10627\n",
      "10622\n",
      "10619\n",
      "variant_calling\n",
      "10615\n",
      "10594\n",
      "10584\n",
      "10635\n",
      "10632\n",
      "10628\n",
      "10627\n",
      "10622\n",
      "10619\n"
     ]
    }
   ],
   "source": [
    "transcript_gene=pd.read_csv(os.path.join(GENOMEDIR,\"/biomart.v38.geneid_transid_genetype.csv\"),usecols=[0,1], names=['gene_id','ID'], skiprows=1)\n",
    "INDIR=DIR+\"/analysis/11_PeptideBindingMHC\"\n",
    "\n",
    "folders = [f.name for f in os.scandir(INDIR) if f.is_dir()]\n",
    "\n",
    "for f in folders:\n",
    "    print(f)\n",
    "    for p in patients_id:\n",
    "        print(p)\n",
    "        full_dir=INDIR+\"/\"+f+\"/\"+p\n",
    "        OUTFILE=full_dir+\"/\"+p+\"_peptides.csv\"\n",
    "        summary_OUTFILE=full_dir+\"/\"+p+\"_summary_total_peptides.csv\"\n",
    "        for file in os.listdir(full_dir):\n",
    "            if file.endswith(\".xls\"):\n",
    "                with open(summary_OUTFILE, 'w') as out:\n",
    "                    out.write(\"type,num_peptids,num_peptids_affinity,total\\n\")\n",
    "                    netmhcpan=full_dir+\"/\"+file\n",
    "                    df = pd.read_csv(netmhcpan, sep=\"\\t\",skiprows=1)\n",
    "                    selected_df = df[['Peptide','ID','NB']]\n",
    "                    total_peptides = len(selected_df.index)\n",
    "                    temp = selected_df[selected_df['NB'] > 0]\n",
    "                    binding_AF = len(temp.index)\n",
    "                    out.write(\"%s,%s,%s,total\\n\"%(f,str(total_peptides),str(binding_AF)))\n",
    "                    \n",
    "                    if f == \"noncanonical_CIPHER\":\n",
    "                        novel = selected_df[selected_df[\"ID\"].str.contains('STRG')]\n",
    "                        total_peptidesN = len(novel.index)\n",
    "                        tempN = novel[novel['NB'] > 0]\n",
    "                        binding_AFN = len(tempN.index)\n",
    "                        out.write(\"%s,%s,%s,novel\\n\"%(f,str(total_peptidesN),str(binding_AFN)))\n",
    "\n",
    "                        ENST = selected_df[selected_df[\"ID\"].str.contains('ENST')]\n",
    "                        total_peptidesK = len(ENST.index)\n",
    "                        tempK = ENST[ENST['NB'] > 0]\n",
    "                        binding_AFK = len(tempK.index)\n",
    "                        out.write(\"%s,%s,%s,annotated\\n\"%(f,str(total_peptidesK),str(binding_AFK)))\n",
    "                              \n",
    "                              \n",
    "                    temp_genes = temp.merge(transcript_gene, how='left', on=['ID'])\n",
    "                    temp_genes.rename(columns={'ID':'transcript_id'}, inplace=True)      \n",
    "                    temp_genes.to_csv(OUTFILE, index=False)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C** | general output file with binding affinity information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDIR=DIR+\"/analysis/11_PeptideBindingMHC\"\n",
    "folders = [f.name for f in os.scandir(INDIR) if f.is_dir()] #if variant calling is already performed, this line shoul be commented and the next one uncommented\n",
    "#folders=['noncanonical_CIPHER','canonical_CDS','translation_evidence_NOCDS']\n",
    "\n",
    "output=INDIR+\"/binding_affinity.csv\"\n",
    "absolute_df = pd.DataFrame()\n",
    "\n",
    "for p in patients_id:\n",
    "    for f in folders:\n",
    "        full_dir=INDIR+\"/\"+f+\"/\"+p+\"/\"\n",
    "        file=full_dir+p+\"_summary_total_peptides.csv\"\n",
    "        df = pd.read_csv(file, header=0)\n",
    "        df['patient'] = p\n",
    "        absolute_df = pd.concat([absolute_df, df])\n",
    "\n",
    "cols = list(absolute_df.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "absolute_df = absolute_df[cols]\n",
    "absolute_df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At peptide level, are there redundancies? The same peptide several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10615\n",
      "DUPLIS:  395 \tTOTAL:  145834  it represents a: 0.27\n",
      "10594\n",
      "DUPLIS:  427 \tTOTAL:  165410  it represents a: 0.26\n",
      "10584\n",
      "DUPLIS:  682 \tTOTAL:  197697  it represents a: 0.34\n",
      "10635\n",
      "DUPLIS:  669 \tTOTAL:  203225  it represents a: 0.33\n",
      "10632\n",
      "DUPLIS:  567 \tTOTAL:  169336  it represents a: 0.33\n",
      "10628\n",
      "Patient 10628 has no hits for translation evidence proteins\n",
      "DUPLIS:  479 \tTOTAL:  182478  it represents a: 0.26\n",
      "10627\n",
      "DUPLIS:  709 \tTOTAL:  285313  it represents a: 0.25\n",
      "10622\n",
      "DUPLIS:  486 \tTOTAL:  168878  it represents a: 0.29\n",
      "10619\n",
      "DUPLIS:  637 \tTOTAL:  204657  it represents a: 0.31\n"
     ]
    }
   ],
   "source": [
    "INDIR=DIR+\"/analysis/11_PeptideBindingMHC\"\n",
    "folders = [f.name for f in os.scandir(INDIR) if f.is_dir()]\n",
    "\n",
    "for p in patients_id:\n",
    "    print(p)\n",
    "    total=pd.DataFrame()\n",
    "    for f in folders:\n",
    "        INDIR=DIR+\"/analysis/11_PeptideBindingMHC\"\n",
    "        full_dir=INDIR+\"/\"+f+\"/\"+p+\"/\"\n",
    "        OUTFILE=INDIR+\"/\"+p+\"_total_peptides.csv\"\n",
    "        file=full_dir+p+\"_peptides.csv\"\n",
    "        try:\n",
    "            df = pd.read_csv(file,header=0)\n",
    "        except:\n",
    "            print(\"Patient\",p,\"has no hits for translation evidence proteins\")\n",
    "        df['method'] = f\n",
    "        total = pd.concat([total,df],ignore_index=True)\n",
    "    sorted_df = total.sort_values(by=['Peptide'])\n",
    "    duplis = sorted_df[sorted_df.duplicated(keep=False)]\n",
    "    percent=(len(duplis)*100)/len(sorted_df)\n",
    "    print(\"DUPLIS: \",len(duplis),\"\\tTOTAL: \",len(sorted_df),\" it represents a: %.2f\" %(percent))\n",
    "    without_duplis=sorted_df.drop_duplicates() #peptides comming from different genes???\n",
    "    sorted_df.to_csv(OUTFILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tissue expression control (GTEx)\n",
    "\n",
    "GTEx is used as normal control to avoide false positive peptides coming from genes expressed in other healthy tissues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$GENOMEDIR\"\n",
    "\n",
    "cd $1\n",
    "wget https://storage.googleapis.com/gtex_analysis_v8/rna_seq_data/GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GTEx=pd.read_csv(os.path.join(GENOMEDIR,\"GTEx_Analysis_2017-06-05_v8_RNASeQCv1.1.9_gene_median_tpm.gct\"), sep=\"\\t\", skiprows=2)\n",
    "GTEx.drop('Description', inplace=True, axis=1)\n",
    "GTEx['Name'] = GTEx['Name'].str[:-2]\n",
    "nc = pd.read_csv(DIR+\"/analysis/09_CIPHER/common_noncoding_genes.csv\")\n",
    "to_compare = nc.gene_id.values.tolist()\n",
    "\n",
    "output = DIR+\"/analysis/09_CIPHER/common_noncoding_genes_GTEx.csv\" #from all the non-protein-coding genes, which ones are present in GTEx\n",
    "\n",
    "shared = GTEx[GTEx['Name'].isin(to_compare)]\n",
    "shared.to_csv(output)\n",
    "\n",
    "c = pd.read_csv(DIR+\"/analysis/09_CIPHER/common_coding_genes.csv\") #from all the protein-coding genes, which ones are present in GTEx\n",
    "to_compare_c = c.gene_id.values.tolist()\n",
    "\n",
    "output_c = DIR+\"/analysis/09_CIPHER/common_coding_genes_GTEx.csv\"\n",
    "\n",
    "shared_c = GTEx[GTEx['Name'].isin(to_compare_c)]\n",
    "shared_c.to_csv(output_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 218\n",
      "[1] \"out of:\"\n",
      "[1] 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Saving 6.67 x 6.67 in image\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 16\n",
      "[1] \"out of:\"\n",
      "[1] 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rpy2.rinterface_lib.callbacks:R[write to console]: Saving 6.67 x 6.67 in image\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R -i DIR,GENOMEDIR\n",
    "\n",
    "#####NONCODING\n",
    "GTEx_raw = read.csv(paste0(DIR,\"/analysis/09_CIPHER/common_noncoding_genes_GTEx.csv\"), row.names = 1)\n",
    "GTEx <- GTEx_raw\n",
    "GTEx_raw_long <- GTEx %>% pivot_longer(cols=!c(\"Name\"), values_to = \"FPKM\", names_to = \"tissue\")\n",
    "GTEx_raw_long$logFPKM <- log10(GTEx_raw_long$FPKM)\n",
    "tissue_group <- gsub(\"\\\\..*\", \"\", names(GTEx_raw[,2:55]))\n",
    "\n",
    "temp <- data.frame(tissue_group, names(GTEx_raw[,2:55]))\n",
    "names(temp)[2] <- \"tissue\"\n",
    "\n",
    "GTEx_raw_long <- merge(temp, GTEx_raw_long, by=\"tissue\")\n",
    "\n",
    "nb.cols <- 54\n",
    "mycolors <- colorRampPalette(brewer.pal(12, \"Paired\"))(nb.cols)\n",
    "\n",
    "ggplot(GTEx_raw_long, aes(x=tissue_group, y=logFPKM, fill=tissue_group))+\n",
    "  geom_boxplot(show.legend = FALSE) +\n",
    "  scale_fill_manual(values=mycolors) +\n",
    "  theme(axis.text.x = element_text(angle = 90, hjust=1))\n",
    "\n",
    "GTEx$sums <- rowSums(GTEx[,2:55])\n",
    "\n",
    "GTEx_new <- GTEx[GTEx$sums == 0,]\n",
    "GTEx <- GTEx[GTEx$sums != 0,]\n",
    "\n",
    "\n",
    "GTEx_out_FPKM1 <- GTEx[rowSums(GTEx[,2:55] > 1) > 15,]\n",
    "GTEx_out_FPKM05 <- GTEx[rowSums(GTEx[,2:55] > 0.5) > 15,]\n",
    "\n",
    "GTEx <- anti_join(GTEx, GTEx_out_FPKM05, by = \"Name\")\n",
    "GTEx_long <- GTEx %>% pivot_longer(cols=!c(\"Name\"), values_to = \"FPKM\", names_to = \"tissue\")\n",
    "GTEx_long <- merge(temp, GTEx_long, by=\"tissue\")\n",
    "\n",
    "not_useful_tissues <- c(\"Adipose\",\"Adrenal\",\"Artery\",\"Bladder\",\"Breasts\",\"Cells\",\"Cervix\",\"Colon\",\"Esophagus\",\"Fallopian\",\"Heart\",\"Kidney\",\"Liver\",\"Lung\",\"Minor\",\"Muscle\",\"Nerve\",\"Pancreas\",\"Pituitary\",\"Prostate\",\"Skin\",\"Small\",\"Spleen\",\"Stomach\",\"Thyroid\",\"Uterus\",\"Vagina\",\"Whole\")\n",
    "GTEx_long_not_useful <- GTEx_long[GTEx_long$tissue_group %in% not_useful_tissues,] #remove all the genes present in some of the tissue we are not interested in\n",
    "\n",
    "GTEx_not_useful <- GTEx_long_not_useful[,-c(2,6)] %>% pivot_wider(names_from=\"tissue\", values_from = \"FPKM\")\n",
    "GTEx_not_useful$sums <- rowSums(GTEx_not_useful[,2:24])\n",
    "GTEx_useful <- GTEx_not_useful[GTEx_not_useful$sums == 0,]\n",
    "\n",
    "\n",
    "####WE ARE INTERESTED IN GTEX_NEW AND GTEX_USEFUL\n",
    "\n",
    "ids_new <- GTEx_new %>% select(Name)\n",
    "ids_useful <- GTEx_useful %>% select(Name)\n",
    "ids <- rbind(ids_new, ids_useful)\n",
    "names(ids) <- c(\"gene_id\")\n",
    "\n",
    "trans_gene <- read.csv(paste0(GENOMEDIR,\"/biomart.v38.geneid_transid_genetype.csv\"))\n",
    "trans_gene <- trans_gene %>% select(1,3)\n",
    "names(trans_gene) <- c(\"gene_id\",\"gene_name\")\n",
    "\n",
    "ids <- merge(ids, trans_gene, by=\"gene_id\")\n",
    "print(nrow(ids))\n",
    "print(\"out of:\")\n",
    "print(nrow(GTEx))\n",
    "\n",
    "common <- read.csv(paste0(DIR,\"/analysis/09_CIPHER/common_noncoding_genes.csv\"))\n",
    "common_ids <- merge(ids, common[,c(\"transcript_id\",\"gene_id\",\"n\")], by=\"gene_id\")\n",
    "\n",
    "sorted_common_ids <- common_ids[order(common_ids$n, decreasing=TRUE),]\n",
    "write.table(sorted_common_ids, paste0(DIR,\"/analysis/09_CIPHER/common_noncoding_genes_tissues_checked.csv\"), col.names=TRUE, row.names=FALSE, quote=FALSE, sep=\",\")\n",
    "\n",
    "ggplot(sorted_common_ids, aes(x=n)) +\n",
    "  geom_bar(fill=\"#004D40\") +\n",
    "  geom_text(stat=\"count\", aes(label=..count..), vjust=-1, size = 2.5) +\n",
    "  ggtitle(\"Common non-coding genes across patients not present in other tissues | lncRNA & processed_pseudogenes\") +\n",
    "  theme(axis.title.x = element_blank(), axis.title.y = element_blank(), plot.title = element_text(face=\"bold\", size = 9), legend.position = \"none\") \n",
    "ggsave(file.path(DIR,\"/results/plots/common_noncoding_genes_GTEx_patients.png\"))\n",
    "\n",
    "#####CODING\n",
    "GTEx_raw = read.csv(paste0(DIR,\"/analysis/09_CIPHER/common_coding_genes_GTEx.csv\"), row.names = 1)\n",
    "GTEx <- GTEx_raw\n",
    "GTEx_raw_long <- GTEx %>% pivot_longer(cols=!c(\"Name\"), values_to = \"FPKM\", names_to = \"tissue\")\n",
    "GTEx_raw_long$logFPKM <- log10(GTEx_raw_long$FPKM)\n",
    "tissue_group <- gsub(\"\\\\..*\", \"\", names(GTEx_raw[,2:55]))\n",
    "\n",
    "temp <- data.frame(tissue_group, names(GTEx_raw[,2:55]))\n",
    "names(temp)[2] <- \"tissue\"\n",
    "\n",
    "GTEx_raw_long <- merge(temp, GTEx_raw_long, by=\"tissue\")\n",
    "\n",
    "nb.cols <- 54\n",
    "mycolors <- colorRampPalette(brewer.pal(12, \"Paired\"))(nb.cols)\n",
    "\n",
    "ggplot(GTEx_raw_long, aes(x=tissue_group, y=logFPKM, fill=tissue_group))+\n",
    "  geom_boxplot(show.legend = FALSE) +\n",
    "  scale_fill_manual(values=mycolors) +\n",
    "  theme(axis.text.x = element_text(angle = 90, hjust=1))\n",
    "\n",
    "GTEx$sums <- rowSums(GTEx[,2:55])\n",
    "\n",
    "GTEx_new <- GTEx[GTEx$sums == 0,]\n",
    "GTEx <- GTEx[GTEx$sums != 0,]\n",
    "\n",
    "\n",
    "GTEx_out_FPKM1 <- GTEx[rowSums(GTEx[,2:55] > 1) > 15,]\n",
    "GTEx_out_FPKM05 <- GTEx[rowSums(GTEx[,2:55] > 0.5) > 15,]\n",
    "\n",
    "GTEx <- anti_join(GTEx, GTEx_out_FPKM05, by = \"Name\")\n",
    "GTEx_long <- GTEx %>% pivot_longer(cols=!c(\"Name\"), values_to = \"FPKM\", names_to = \"tissue\")\n",
    "GTEx_long <- merge(temp, GTEx_long, by=\"tissue\")\n",
    "\n",
    "not_useful_tissues <- c(\"Adipose\",\"Adrenal\",\"Artery\",\"Bladder\",\"Breasts\",\"Cells\",\"Cervix\",\"Colon\",\"Esophagus\",\"Fallopian\",\"Heart\",\"Kidney\",\"Liver\",\"Lung\",\"Minor\",\"Muscle\",\"Nerve\",\"Pancreas\",\"Pituitary\",\"Prostate\",\"Skin\",\"Small\",\"Spleen\",\"Stomach\",\"Thyroid\",\"Uterus\",\"Vagina\",\"Whole\")\n",
    "GTEx_long_not_useful <- GTEx_long[GTEx_long$tissue_group %in% not_useful_tissues,]\n",
    "\n",
    "GTEx_not_useful <- GTEx_long_not_useful[,-c(2,6)] %>% pivot_wider(names_from=\"tissue\", values_from = \"FPKM\")\n",
    "GTEx_not_useful$sums <- rowSums(GTEx_not_useful[,2:24])\n",
    "GTEx_useful <- GTEx_not_useful[GTEx_not_useful$sums == 0,]\n",
    "\n",
    "\n",
    "####WE ARE INTERESTED IN GTEX_NEW AND GTEX_USEFUL\n",
    "\n",
    "ids_new <- GTEx_new %>% select(Name)\n",
    "ids_useful <- GTEx_useful %>% select(Name)\n",
    "ids <- rbind(ids_new, ids_useful)\n",
    "names(ids) <- c(\"gene_id\")\n",
    "\n",
    "ids <- merge(ids, trans_gene, by=\"gene_id\")\n",
    "print(nrow(ids))\n",
    "print(\"out of:\")\n",
    "print(nrow(GTEx))\n",
    "\n",
    "common <- read.csv(paste0(DIR,\"/analysis/09_CIPHER/common_coding_genes.csv\"))\n",
    "common_ids <- merge(ids, common[,c(\"transcript_id\",\"gene_id\",\"n\")], by=\"gene_id\")\n",
    "\n",
    "sorted_common_ids <- common_ids[order(common_ids$n, decreasing=TRUE),]\n",
    "write.table(sorted_common_ids, paste0(DIR,\"/analysis/09_CIPHER/common_coding_genes_tissues_checked.csv\"), col.names=TRUE, row.names=FALSE, quote=FALSE, sep=\",\")\n",
    "\n",
    "ggplot(sorted_common_ids, aes(x=n)) +\n",
    "  geom_bar(fill=\"#004D40\") +\n",
    "  geom_text(stat=\"count\", aes(label=..count..), vjust=-1, size = 2.5) +\n",
    "  ggtitle(\"Common non-coding genes across patients not present in other tissues | lncRNA & processed_pseudogenes\") +\n",
    "  theme(axis.title.x = element_blank(), axis.title.y = element_blank(), plot.title = element_text(face=\"bold\", size = 9), legend.position = \"none\") \n",
    "ggsave(file.path(DIR,\"/results/plots/common_coding_genes_GTEx_patients.png\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10615\n",
      "noncanonical_CIPHER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3295328720.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  STRG_df['gene_id'] = STRG_df['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical_CDS\n",
      "translation_evidence_NOCDS\n",
      "10594\n",
      "noncanonical_CIPHER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3295328720.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  STRG_df['gene_id'] = STRG_df['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical_CDS\n",
      "translation_evidence_NOCDS\n",
      "10584\n",
      "noncanonical_CIPHER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3295328720.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  STRG_df['gene_id'] = STRG_df['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical_CDS\n",
      "translation_evidence_NOCDS\n",
      "10635\n",
      "noncanonical_CIPHER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3295328720.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  STRG_df['gene_id'] = STRG_df['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical_CDS\n",
      "translation_evidence_NOCDS\n",
      "10632\n",
      "noncanonical_CIPHER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3295328720.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  STRG_df['gene_id'] = STRG_df['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical_CDS\n",
      "translation_evidence_NOCDS\n",
      "10628\n",
      "noncanonical_CIPHER\n",
      "canonical_CDS\n",
      "translation_evidence_NOCDS\n",
      "10627\n",
      "noncanonical_CIPHER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3295328720.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  STRG_df['gene_id'] = STRG_df['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical_CDS\n",
      "translation_evidence_NOCDS\n",
      "10622\n",
      "noncanonical_CIPHER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3295328720.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  STRG_df['gene_id'] = STRG_df['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canonical_CDS\n",
      "translation_evidence_NOCDS\n",
      "10619\n",
      "noncanonical_CIPHER\n",
      "canonical_CDS\n",
      "translation_evidence_NOCDS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3295328720.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  STRG_df['gene_id'] = STRG_df['transcript_id']\n"
     ]
    }
   ],
   "source": [
    "#select peptides resulting from genes not expressed in adult tissues according to GTEx\n",
    "\n",
    "folders = [f.name for f in os.scandir(INDIR) if f.is_dir()] #if variant calling is already performed, this line shoul be commented and the next one uncommented\n",
    "#folders=['noncanonical_CIPHER','canonical_CDS','translation_evidence_NOCDS']\n",
    "for p in patients_id:\n",
    "    print(p)\n",
    "    for f in folders:\n",
    "        print(f)\n",
    "        if f == \"canonical_CDS\":\n",
    "            checked=pd.read_csv(DIR+\"/analysis/09_CIPHER/common_coding_genes_tissues_checked.csv\", header=0)\n",
    "            to_compare=checked.gene_id.values.tolist()\n",
    "        else:\n",
    "            checked=pd.read_csv(DIR+\"/analysis/09_CIPHER/common_noncoding_genes_tissues_checked.csv\", header=0)\n",
    "            to_compare=checked.gene_id.values.tolist()\n",
    "            \n",
    "        match=pd.DataFrame()\n",
    "        INDIR=DIR+\"/analysis/11_PeptideBindingMHC/\"+f+\"/\"+p\n",
    "        filename= p+\"_peptides.csv\"\n",
    "        \n",
    "        outname= p+\"_peptides_GTEx.csv\" #generate file with those peptides coming from genes that have been selected after GTEx control\n",
    "        binding_affinity = pd.read_csv(INDIR+\"/\"+filename)\n",
    "        match = binding_affinity[binding_affinity['gene_id'].isin(to_compare)]\n",
    "        try:\n",
    "            STRG_df = binding_affinity[binding_affinity['transcript_id'].str.contains('STRG')]\n",
    "            STRG_df['gene_id'] = STRG_df['transcript_id']\n",
    "            match = pd.concat([match,STRG_df])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        match.to_csv(os.path.join(INDIR,outname), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring netMHCpan output with GTEx filter\n",
    "\n",
    "Summary file **A** how many peptides have binding affinity respect to the total number of peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noncanonical_CIPHER\n",
      "10615\n",
      "                  type  num_peptids  num_peptids_affinity      total\n",
      "0  noncanonical_CIPHER      1131199                141076      total\n",
      "1  noncanonical_CIPHER          229                    19      novel\n",
      "2  noncanonical_CIPHER      1130970                141057  annotated\n",
      "10594\n",
      "                  type  num_peptids  num_peptids_affinity      total\n",
      "0  noncanonical_CIPHER      1134382                158852      total\n",
      "1  noncanonical_CIPHER         7016                  1056      novel\n",
      "2  noncanonical_CIPHER      1127366                157796  annotated\n",
      "10584\n",
      "                  type  num_peptids  num_peptids_affinity      total\n",
      "0  noncanonical_CIPHER      1161637                186978      total\n",
      "1  noncanonical_CIPHER          592                    88      novel\n",
      "2  noncanonical_CIPHER      1161045                186890  annotated\n",
      "10635\n",
      "                  type  num_peptids  num_peptids_affinity      total\n",
      "0  noncanonical_CIPHER      1033621                201101      total\n",
      "1  noncanonical_CIPHER         1527                   329      novel\n",
      "2  noncanonical_CIPHER      1032094                200772  annotated\n",
      "10632\n",
      "                  type  num_peptids  num_peptids_affinity      total\n",
      "0  noncanonical_CIPHER      1087516                165411      total\n",
      "1  noncanonical_CIPHER           88                    18      novel\n",
      "2  noncanonical_CIPHER      1087428                165393  annotated\n",
      "10628\n",
      "                  type  num_peptids  num_peptids_affinity      total\n",
      "0  noncanonical_CIPHER       974339                181718      total\n",
      "1  noncanonical_CIPHER            0                     0      novel\n",
      "2  noncanonical_CIPHER       974339                181718  annotated\n",
      "10627\n",
      "                  type  num_peptids  num_peptids_affinity      total\n",
      "0  noncanonical_CIPHER      1256233                263784      total\n",
      "1  noncanonical_CIPHER          703                   134      novel\n",
      "2  noncanonical_CIPHER      1255530                263650  annotated\n",
      "10622\n",
      "                  type  num_peptids  num_peptids_affinity      total\n",
      "0  noncanonical_CIPHER      1015746                162957      total\n",
      "1  noncanonical_CIPHER         7170                  1236      novel\n",
      "2  noncanonical_CIPHER      1008576                161721  annotated\n",
      "10619\n",
      "                  type  num_peptids  num_peptids_affinity      total\n",
      "0  noncanonical_CIPHER      1125669                202975      total\n",
      "1  noncanonical_CIPHER          272                    48      novel\n",
      "2  noncanonical_CIPHER      1125397                202927  annotated\n",
      "canonical_CDS\n",
      "10615\n",
      "10594\n",
      "10584\n",
      "10635\n",
      "10632\n",
      "10628\n",
      "10627\n",
      "10622\n",
      "10619\n",
      "translation_evidence_NOCDS\n",
      "10615\n",
      "10594\n",
      "10584\n",
      "10635\n",
      "10632\n",
      "10628\n",
      "10627\n",
      "10622\n",
      "10619\n"
     ]
    }
   ],
   "source": [
    "transcript_gene=pd.read_csv(os.path.join(GENOMEDIR,\"/biomart.v38.geneid_transid_genetype.csv\"),usecols=[0,1], names=['gene_id','ID'], skiprows=1)\n",
    "INDIR=DIR+\"/analysis/11_PeptideBindingMHC\"\n",
    "\n",
    "#folders = [f.name for f in os.scandir(INDIR) if f.is_dir()]\n",
    "folders=['noncanonical_CIPHER','canonical_CDS','translation_evidence_NOCDS']\n",
    "\n",
    "for f in folders:\n",
    "    print(f)\n",
    "    for p in patients_id:\n",
    "        print(p)\n",
    "        full_dir=INDIR+\"/\"+f+\"/\"+p\n",
    "        gtex_file=full_dir+\"/\"+p+\"_peptides_GTEx.csv\"\n",
    "        summary_OUTFILE=full_dir+\"/\"+p+\"_summary_total_peptides_GTEx.csv\"\n",
    "        file=p+\"_summary_total_peptides.csv\"\n",
    "        with open(summary_OUTFILE, 'w') as out:\n",
    "            out.write(\"type,num_peptids,num_peptids_affinity,total\\n\")\n",
    "            full_summary=full_dir+\"/\"+file\n",
    "            df = pd.read_csv(full_summary, header=0)\n",
    "            total_df = df[df[\"total\"] == 'total']\n",
    "            total_peptides = total_df.iat[0,1]\n",
    "\n",
    "\n",
    "            gtex_df = pd.read_csv(gtex_file, header=0)\n",
    "            peptides = gtex_df.Peptide.values.tolist()\n",
    "            binding_AF = len(gtex_df.index)\n",
    "            out.write(\"%s,%s,%s,total\\n\"%(f,str(total_peptides),str(binding_AF)))\n",
    "\n",
    "            if f == \"noncanonical_CIPHER\":\n",
    "                print(df)\n",
    "                novel = df[df[\"total\"] == 'novel']\n",
    "                total_peptidesN = novel.iat[0,1]\n",
    "                novel_gtex = gtex_df[gtex_df['transcript_id'].str.contains('STRG')]\n",
    "                binding_AFN = len(novel_gtex.index)\n",
    "                out.write(\"%s,%s,%s,novel\\n\"%(f,str(total_peptidesN),str(binding_AFN)))\n",
    "\n",
    "                ENST = df[df[\"total\"] == 'annotated']\n",
    "                total_peptidesK = ENST.iat[0,1]\n",
    "\n",
    "                enst_gtex = gtex_df[gtex_df['transcript_id'].str.contains('ENST')]\n",
    "                binding_AFK = len(enst_gtex.index)\n",
    "                out.write(\"%s,%s,%s,annotated\\n\"%(f,str(total_peptidesK),str(binding_AFK)))\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C** | general output file with binding affinity information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDIR=DIR+\"/analysis/11_PeptideBindingMHC\"\n",
    "folders = [f.name for f in os.scandir(INDIR) if f.is_dir()]\n",
    "#folders=['noncanonical_CIPHER','canonical_CDS','translation_evidence_NOCDS']\n",
    "\n",
    "output=INDIR+\"/binding_affinity_GTEx.csv\"\n",
    "absolute_df = pd.DataFrame()\n",
    "\n",
    "for p in patients_id:\n",
    "    for f in folders:\n",
    "        full_dir=INDIR+\"/\"+f+\"/\"+p+\"/\"\n",
    "        \n",
    "        file=full_dir+p+\"_summary_total_peptides_GTEx.csv\"\n",
    "        df = pd.read_csv(file, header=0)\n",
    "\n",
    "        df['patient'] = p\n",
    "        absolute_df = pd.concat([absolute_df, df])\n",
    "\n",
    "cols = list(absolute_df.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "absolute_df = absolute_df[cols]\n",
    "absolute_df.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring novel peptides shared between patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3160070270.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  novel_peptides['gene_id'] = novel_peptides['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplis:  19\n",
      "without duplis:  19\n",
      "10594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3160070270.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  novel_peptides['gene_id'] = novel_peptides['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplis:  1056\n",
      "without duplis:  1054\n",
      "10584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3160070270.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  novel_peptides['gene_id'] = novel_peptides['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplis:  88\n",
      "without duplis:  88\n",
      "10635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3160070270.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  novel_peptides['gene_id'] = novel_peptides['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplis:  329\n",
      "without duplis:  316\n",
      "10632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3160070270.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  novel_peptides['gene_id'] = novel_peptides['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplis:  18\n",
      "without duplis:  18\n",
      "10628\n",
      "with duplis:  0\n",
      "without duplis:  0\n",
      "10627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3160070270.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  novel_peptides['gene_id'] = novel_peptides['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplis:  134\n",
      "without duplis:  134\n",
      "10622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3160070270.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  novel_peptides['gene_id'] = novel_peptides['transcript_id']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with duplis:  1236\n",
      "without duplis:  1154\n",
      "10619\n",
      "with duplis:  48\n",
      "without duplis:  48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10294/3160070270.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  novel_peptides['gene_id'] = novel_peptides['transcript_id']\n"
     ]
    }
   ],
   "source": [
    "INDIR=DIR+\"/analysis/11_PeptideBindingMHC\"\n",
    "\n",
    "total_peptides_df = pd.DataFrame()\n",
    "for p in patients_id:\n",
    "    print(p)\n",
    "    peptides = pd.read_csv(INDIR+\"/\"+p+\"_total_peptides.csv\")\n",
    "    try:\n",
    "        novel_peptides = peptides[peptides['transcript_id'].str.contains('STRG')]\n",
    "        novel_peptides['gene_id'] = novel_peptides['transcript_id']\n",
    "        novel_peptides_df = novel_peptides['Peptide']\n",
    "        print(\"with duplis: \",len(novel_peptides_df))\n",
    "\n",
    "        novel_peptides_df = novel_peptides_df.drop_duplicates()\n",
    "        print(\"without duplis: \",len(novel_peptides_df))\n",
    "        total_peptides_df= pd.concat([total_peptides_df, novel_peptides_df])\n",
    "    except:\n",
    "        print(\"Patient \",p,\" has no novel peptides.\")\n",
    "\n",
    "total_peptides_counts = total_peptides_df.value_counts().rename_axis('peptide').reset_index(name='counts')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KGDDENKRI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEIVYNCQI</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REDFRCTLI</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RPQPPGTQA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VEFQLQSHL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>KDNGDTDLF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>KDYDLACLL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>KEAKNLHKR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>KECGSGLML</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>YYTIVISLH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2761 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        peptide  counts\n",
       "0     KGDDENKRI       3\n",
       "1     DEIVYNCQI       3\n",
       "2     REDFRCTLI       2\n",
       "3     RPQPPGTQA       2\n",
       "4     VEFQLQSHL       2\n",
       "...         ...     ...\n",
       "2756  KDNGDTDLF       1\n",
       "2757  KDYDLACLL       1\n",
       "2758  KEAKNLHKR       1\n",
       "2759  KECGSGLML       1\n",
       "2760  YYTIVISLH       1\n",
       "\n",
       "[2761 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_peptides_counts.to_csv(DIR+\"/analysis/novel_neoantigens.csv\", index=False)\n",
    "total_peptides_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
